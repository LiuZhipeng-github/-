# 数据结构与算法之第六篇.树

## 概述

树是一种非线性表结构，比线性表的数据结构要复杂得多：

|           树的种类           |
| :--------------------------: |
|            二叉树            |
|          完全二叉树          |
| **二叉查找树（二叉排序树）** |
|           哈夫曼树           |
|            递归树            |
|          B树、B+树           |
|            红黑树            |
|            递归树            |

“树”的特征：

![1570444279777](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444279777.png)



“树”这种数据结构里面每个元素叫作“节点”；用来连线相邻节点之间的关系叫作“父子关系”。

比如下面这幅图，A 节点就是 B 节点的**父节点**，B 节点是 A 节点的**子节点**。B、C、D 这三个节点的父节点是同一个节点，所以它们之间互称为**兄弟节点**。没有父节点的节点叫**根节点**，也就是图中的节点 E。没有子节点的节点叫作**叶子节点**或者**叶节点**，比如图中的 G、H、I、J、K、L 都是叶子节点。

![1570444335291](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444335291.png)

**高度**（Height）、**深度**（Depth）、**层**（Level）的定义：

```
节点的高度=节点到叶子节点的最长路径(边数)
节点的深度=根节点到这个节点所经历的边的个数
节点的层数=节点的深度+1
树的高度=根节点的高度
```

![1570444363236](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444363236.png)

“高度”是从下往上度量，从最底层开始计数计数的起点是 0。

“深度”是从上往下度量，从根结点开始度量计数起点也是 0。

“层数”跟深度的计算类似，不过计数起点是 1。

## 1、二叉树（Binary Tree）

二叉树的每个节点最多有两个子节点，分别是左子节点和右子节点。二叉树中，有两种比较特殊的树，分别是满二叉树和完全二叉树。满二叉树又是完全二叉树的一种特殊情况。

二叉树既可以用链式存储，也可以用数组顺序存储。数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树用数组存储会比较浪费存储空间。除此之外，二叉树里非常重要的操作就是前、中、后序遍历操作，遍历的时间复杂度是 O(n)，需要用递归代码来实现。



二叉树是树的一种，特点是每个节点最多有两个子节点，分别是**左子节点**和**右子节点**。不过，二叉树有的节点只有左子节点，有的节点只有右子节点：

![1570444377068](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444377068.png)

上图编号 2 的二叉树中，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫作**满二叉树**。

编号 3 的二叉树中，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作**完全二叉树**。

## 2、完全二叉树

完全二叉树和非完全二叉树的区别：

![1570444390843](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444390843.png)

最后一层的叶子节点靠左排列的才叫完全二叉树，如果靠右排列就不能叫完全二叉树了。

存储一棵二叉树有两种方法，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。

**链式存储法**中每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。从根节点开始可以通过左右子节点的指针，把整棵树都串起来。这种存储方式我们比较常用。大部分二叉树代码都是通过这种结构来实现的。

![1570444403668](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444403668.png)

基于数组的**顺序存储法**：把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 * i = 2 的位置，右子节点存储在 2 * i + 1 = 3 的位置。以此类推，B 节点的左子节点存储在 2 * i = 2 * 2 = 4 的位置，右子节点存储在 2 * i + 1 = 2 * 2 + 1 = 5 的位置。

![1570444415962](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444415962.png)

如果节点 X 存储在数组中下标为 i 的位置，左子节点的下标为 2 * i ，右子节点的下标为 2 * i + 1。反过来，下标为 i/2 的位置存储就是它的父节点。通过这种方式，只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），就可以通过下标计算，把整棵树都串起来。

一棵完全二叉树仅仅“浪费”了一个下标为 0 的存储位置。如果是非完全二叉树，会浪费比较多的数组存储空间：

![1570444429469](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444429469.png)

如果某棵二叉树是一棵完全二叉树，用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要存储额外的左右子节点的指针。

堆其实就是一种完全二叉树，最常用的存储方式是数组。

### 2.1 二叉树的遍历

将二叉树所有节点都遍历打印出来有三种方法，**前序遍历**、**中序遍历**和**后序遍历**。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。

- 前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
- 中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
- 后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。

![1570444448382](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444448382.png)

**实际上，二叉树的前、中、后序遍历就是一个递归的过程**。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。

写递推公式的关键就是，如果要解决问题 A，就假设子问题 B、C 已经解决，然后再来看如何利用 B、C 来解决 A。前、中、后序遍历的递推公式：

```c
前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
 
中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)
 
后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
```

java伪代码：

```java
void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}
 
void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}
 
void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
```

**二叉树遍历的时间复杂度：**遍历过程中每个节点最多会被访问两次，所以遍历操作的时间复杂度跟节点的个数 n 成正比，二叉树遍历的时间复杂度是 O(n)。

python代码实现：

```python
from typing import Optional


class TreeNode():
    def __init__(self, value):
        self.val = value
        self.left = None
        self.right = None


# 前序遍历
def pre_order(root: Optional[TreeNode]):
    if root:
        yield root.val
        yield from pre_order(root.left)
        yield from pre_order(root.right)


# 中序遍历
def in_order(root: Optional[TreeNode]):
    if root:
        yield from in_order(root.left)
        yield root.val
        yield from in_order(root.right)


# 后序遍历
def post_order(root: Optional[TreeNode]):
    if root:
        yield from post_order(root.left)
        yield from post_order(root.right)
        yield root.val
```



### 2.2 按层次遍历二叉树

除了前、中、后序三种二叉树遍历方式外还有按层遍历这种遍历方式。

实现思路：

按照 广度优先的遍历算法的思路，引入一个队列，根节点先入队列，然后开始从队列头部取元素，每取一个元素则先打印当前元素，然后依次将左右子节点加入队列，若左子节点或右子节点为空则跳过此步。

python实现代码：

```python
from collections import deque


# 层级遍历
def layer_order(root: TreeNode):
    if not root: return
    queue = deque([root])
    while queue:
        e: TreeNode = queue.popleft()
        yield e.val
        if e.left: queue.append(e.left)
        if e.right: queue.append(e.right)
```

对应leetcode题目：

 https://leetcode.com/problems/binary-tree-level-order-traversal/ 

给定一个二叉树，返回其按层次遍历的节点值。 （即逐层地，从左到右访问所有节点）。

例如:
给定二叉树: [3,9,20,null,null,15,7],

        3
       / \
      9  20
        /  \
       15   7

返回其层次遍历结果：

```
[
  [3],
  [9,20],
  [15,7]
]
```

python代码实现：

```python
def level_order(root: TreeNode):
    levels = []
    if not root:
        return levels
    level = 0
    queue = deque([root])
    while queue:
        levels.append([])
        for i in range(len(queue)):
            node = queue.popleft()
            levels[level].append(node.val)
            if node.left:
                queue.append(node.left)
            if node.right:
                queue.append(node.right)
        level += 1

    return levels
```



## 3、二叉查找树（Binary Search Tree）

二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。二叉查找树支持动态数据集合的快速插入、删除、查找操作。

二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值都小于这个节点的值，而右子树每个节点的值都大于这个节点的值:

![1570444524770](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444524770.png)

### 3.1  二叉查找树的查找操作

先取根节点，如果它等于要查找的数据就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。

![1570444541558](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444541558.png)

### 3.2  二叉查找树的插入操作

二叉查找树的插入过程需要从根节点开始，依次比较要插入的数据和节点的大小关系。

如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。

![1570444560417](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444560417.png)

### 3. 3 二叉查找树的删除操作

针对要删除节点的子节点个数的不同需要分2种情况来处理。

如果要删除的节点只有一个子节点（只有左子节点或者右子节点）或没有子节点（左右子节点均为Null），只需要要将要删除节点的父节点的指针指向要删除节点的子节点。比如下图中删除节点 55、 13。

如果要删除的节点有两个子节点。需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再按照上面方法删除掉这个最小节点。比如下图中的删除节点 18。（用左子树的最大节点进行替换也可以）

![1570444574980](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444574980.png)

关于二叉查找树的删除操作，最简单的方法是单纯将要删除的节点标记为“已删除”并不真正从树中将这个节点去掉。这样原本删除的节点还需要存储在内存中，缺点是比较浪费内存空间。



### 3.4 二叉查找树的其他操作

二叉查找树中还可以支持**快速地查找最大节点和最小节点、前驱节点和后继节点**。

二叉查找树也叫作二叉排序树，**中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)**。

python代码实现：

```python
    def find_min(self) -> Optional[TreeNode]:
        if self.tree is None: return None
        p = self.tree
        while p.left:
            p = p.left
        return p

    def find_max(self) -> Optional[TreeNode]:
        if self.tree is None: return None
        p = self.tree
        while p.right:
            p = p.right
        return p

    def _in_order(self, root: Optional[TreeNode]):
        if root:
            yield from self._in_order(root.left)
            yield root.data
            yield from self._in_order(root.right)

    def in_order(self) -> list:
        if self.tree is None:
            return []
        return list(self._in_order(self.tree))
```

### 3.5 二叉查找树的python实现代码

```python
from collections import deque
from typing import Optional, List


class TreeNode:
    def __init__(self, data=None):
        self.data = data
        self.left = None
        self.right = None


class BinarySearchTree:
    def __init__(self, val_list=None):
        if val_list is None:
            val_list = []
        self.tree: Optional[TreeNode] = None
        for n in val_list:
            self.insert(n)

    def find(self, data):
        p = self.tree
        while p and p.data != data:
            p = p.left if data < p.data else p.right
        return p

    def insert(self, data):
        if not self.tree:
            self.tree = TreeNode(data)
            return
        pp = None
        p = self.tree
        while p:
            pp = p
            p = p.left if p.data > data else p.right
        if pp.data > data:
            pp.left = TreeNode(data)
        else:
            pp.right = TreeNode(data)

    def delete(self, data):
        p: Optional[TreeNode] = self.tree  # p指向要删除的节点，初始化指向根节点
        pp: Optional[TreeNode] = None  # pp记录的是p的父节点
        while p and p.data != data:
            pp = p
            p = p.right if p.data < data else p.left
        if not p: return  # 没有找到

        if p.left and p.right:  # 查找右子树中最小节点
            min_p = p.right  # 记录右子树的最小节点
            min_pp = p  # minPP表示minP的父节点
            while min_p.left:
                min_pp = min_p
                min_p = min_p.left
            p.data = min_p.data  # 替换数据
            p, pp = min_p, min_pp  # p指向要删除的min_p
        #  删除节点是叶子节点或者仅有一个子节点
        child: Optional[TreeNode] = p.left if p.left else p.right
        if not pp:
            self.tree = child  # 删除的是根节点
        elif pp.left == p:
            pp.left = child
        else:
            pp.right = child

    def find_min(self) -> Optional[TreeNode]:
        if self.tree is None: return None
        p = self.tree
        while p.left:
            p = p.left
        return p

    def find_max(self) -> Optional[TreeNode]:
        if self.tree is None: return None
        p = self.tree
        while p.right:
            p = p.right
        return p

    def _in_order(self, root: Optional[TreeNode]):
        if root:
            yield from self._in_order(root.left)
            yield root.data
            yield from self._in_order(root.right)

    def in_order(self) -> list:
        if self.tree is None:
            return []
        return list(self._in_order(self.tree))

    def __repr__(self):
        return str(self.in_order())

    def __iter__(self):
        return self._in_order(self.tree)

    def draw_tree(self):
        if not self.tree:
            return
        # level = 0
        queue = deque([self.tree])
        while queue:
            length = len(queue)
            if set(queue) == {None}: return
            for i in range(length):
                node = queue.popleft()
                if node:
                    print(node.data, end="")
                    queue.append(node.left)
                    queue.append(node.right)
                else:
                    print(None, end="")
                    queue.append(None)
                    queue.append(None)
                if i != length - 1:
                    print(",", end="")
                else:
                    print()


if __name__ == '__main__':
    nums = [4, 2, 10, 6, 1, 7, 3]
    bst = BinarySearchTree(nums)
    print(bst)
    bst.draw_tree()
    # 插入
    bst.insert(5)
    print(bst)

    print(bst.find(2).data)

    # 删除
    bst.delete(6)
    print(bst)
    bst.delete(4)
    print(bst)
    bst.draw_tree()
    # min max
    print(bst.find_max().data)
    print(bst.find_min().data)

```



### 3.6 支持重复数据的二叉查找树

在实际的软件开发中，在二叉查找树中存储的，是一个包含很多字段的对象。利用对象的某个字段作为键值（key）来构建二叉查找树，对象中的其他字段叫作卫星数据。

如果存储的两个对象键值相同的两种解决方法：

1.二叉查找树中每一个节点存储链表或支持动态扩容的数组，把值相同的数据都存储在同一个节点上。

2.每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，就把这个新插入的数据当作大于这个节点的值来处理，放到这个节点的右子树。

![1570444644303](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444644303.png)

查找数据的时候，遇到值相同的节点并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。

![1570444657714](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444657714.png)

对于删除操作也需要先查找到每个要删除的节点，然后再依次删除。

![1570444672716](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444672716.png)

### 3.7 二叉查找树的时间复杂度分析

二叉查找树的形态各式各样。下图中同一组数据构造的三种二叉查找树，它们的查找、插入、删除操作的执行效率都是不一样的。

不管操作是插入、删除还是查找，**时间复杂度其实都跟树的高度成正比，也就是 O(height)**。

![1570444686811](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444686811.png)

上图中，第一种二叉查找树，根节点的左右子树极度不平衡，已经退化成了链表，所以查找的时间复杂度就变成了 O(n)。

最理想的情况下，二叉查找树是一棵完全二叉树（或满二叉树），插入、删除、查找操作时间复杂度是 $O(logn)$

树的高度就等于最大层数减1，包含 n 个节点的满二叉树中，第一层包含 1 个节点，第二层包含 2 个节点，第三层包含 4 个节点，依次类推，下面一层节点个数是上一层的 2 倍，第 K 层包含的节点个数就是 $2^{K-1}$。

对于完全二叉树来说，最后一层的节点个数在 1 到 $2^{K-1}$个之间（假设最大层数是 K）。 n 满足这样一个关系：
$$
1+2+4+8+...+2^{K-2}+1 <= n <= 1+2+4+8+...+2^{K-2}+2^{K-1} \\
\Rightarrow 2^{K-1} <= n <= 2^K-1 \\
\Rightarrow log_2(n+1) <= K <= log_2{n}+1
$$
K 的范围是$[log_2(n+1),log_2{n}+1]$。完全二叉树的层数小于等于$log_2{n}+1$，即高度小于等于$log_2{n}$。



### 3.8 散列表vs二叉查找树

散列表的优势：

散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 $O(logn)$。

散列表的劣势：

我认为有下面几个原因：

第一，散列表要输出有序的数据，需要先进行排序；二叉查找树只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。

第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定；最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。

第三，因为哈希冲突的存在，散列表的实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。

第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。

最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。

综合这几点，平衡二叉查找树在某些方面还是优于散列表的。

## 4、哈夫曼树

给定n个权值作为n个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。**哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。**

### 4.1 **构造哈夫曼树的算法如下：**

```
1）对给定的n个权值{W1,W2,W3,...,Wi,...,Wn}构成n棵二叉树的初始集合F={T1,T2,T3,...,Ti,..., Tn}，其中每棵二叉树Ti中只有一个权值为Wi的根结点，它的左右子树均为空。
2）在F中选取两棵根结点权值最小的树作为新构造的二叉树的左右子树，新二叉树的根结点的权值为其左右子树的根结点的权值之和。
3）从F中删除这两棵树，并把这棵新的二叉树同样以升序排列加入到集合F中。
4）重复2）和3），直到集合F中只有一棵二叉树为止。
```

假设给定a、b、c、d、e、f的权值分别为{9, 12, 6, 3, 5, 15}，构造哈夫曼树的过程如下：

<img src="%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/format,png.png" alt="img" style="zoom:50%;" />

1、为了方便起见，首先将权值进行从小到大排序即,3, 5, 6, 9,12,15

2、选取最小的两个权值3和5构建子树。3+5 = 8作为3,5的父节点（我们规定要满足左子节点小于右子节点）

3、顺序提取6作为左子节点，8作为右子节点。将6+8 = 14作为其父节点。

4、我们发现14大于接下来的9,12。故将9,12作为子节点，9+12 = 21为其父节点构建一个子树。提取元素15，作为右节点上一步构建的14作为左节点，将14+15 = 29作为他们的父节点构建另一个子树。

5、最后将上述两个子树的父节点21,29分别作为左节点和右节点。将21+29 = 50作为他们的父节点。这样就构造出了一个哈夫曼树。

接下来进行带权路径长的计算：

a，b，f（权值9,12,15）三个元素距父节点的距离都为2

c（权值6）元素距父节点的距离为3

d，e（权值3,5）元素距父节点的距离为4

故这棵哈夫曼树的WPL为：WPL =（9 + 12 + 15）*2 + 6 \* 3 + （3 + 5）* 4 = 122

> 两种方法求解WPL：
>
> （1）各叶子结点权值和路径长度之积的和。
>
> （2）所有非叶子结点的权值之和。

### 4.2 哈夫曼编码

字符串中正好满足a、b、c、d、e、f、h分别出现2, 3, 7, 4, 10, 2,5次，作为他们的权值。按照上述方法构建好哈夫曼树。

![091160FC-332A-48BF-ABC6-883F1CECE6C5_1_105_c](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/091160FC-332A-48BF-ABC6-883F1CECE6C5_1_105_c.jpeg)

## 5、二叉平衡树 

### 5.1 概述

二叉查找树是最常用的一种二叉树，它支持快速插入、删除、查找操作，各个操作的时间复杂度跟树的高度成正比，理想情况下，时间复杂度是 O(logn)。但二叉查找树在频繁的动态更新过程中，可能会出现树的高度远大于 $log_2n$ 的情况，从而导致各个操作的效率下降。极端情况下，二叉树会退化为链表，时间复杂度会退化到 $O(n)$。要解决这个复杂度退化的问题，需要设计一种平衡二叉查找树。

平衡二叉树的严格定义是任意一个节点的左右子树的高度相差不能大于 1。

完全二叉树、满二叉树都是平衡二叉树，非完全二叉树也有可能是平衡二叉树。

![1570444901543](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570444901543.png)

最先被发明的平衡二叉查找树是[AVL 树](https://zh.wikipedia.org/wiki/AVL树)，它严格符合平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。

但是很多平衡二叉查找树并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1），比如红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。

发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。

所以，**平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。**

所以，只要树的高度不比 $log_2n$ 大很多（树的高度仍然是对数量级的），就仍然可以认为这是一个合格的平衡二叉查找树。

### 5.2 AVL树的插入

1、沿着插入方向，找到**最先失衡的节点**，从这个节点开始，沿着插入路径，找三个节点调节平衡，把**那三个节点**的中的中间值作为子树的根，小的作为左子树，大的作为右子树，其他节点根据二叉排序树的性质插入这个二叉平衡树。

![F1B40A6F-216E-4015-828E-C3571CCD6832_1_105_c](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/F1B40A6F-216E-4015-828E-C3571CCD6832_1_105_c.jpeg)

### 5.3 AVL树的删除



### 5.3 ADT实现

插入/删除操作的实现：首先根据key确定位置，实际插入或删除节点。如果这时出现树失衡的情况，设法进行局部调整回复树的平衡。插入和删除操作后的调整都可以在树中的一条路径上一遍完成，因此插入和删除操作的时间代价为O(logn)。

节点：实现AVL树，二叉树的每个节点需要增加一个平衡因子记录。

其余属性和插入删除以外的方法都可以从二叉查找树类中继承。

**插入后的失衡调整**

1. LL失衡和调整

   ```
   @staticmethod
   def LL(a, b):
       """
   
       :param a: 最小非平衡子树的根
       :param b: 最小非平衡子树的根的左子节点
       :return:
       """
       a.left = b.right
       b.right = a
       a.bf = b.bf = 0
       return b
   ```

2. RR失衡和调整

   ```
   @staticmethod
   def RR(a, b):
       a.right = b.left
       b.left = a
       a.bf = b.bf = 0
       return b
   ```

3. LR失衡和调整

   ```
   @staticmethod
       def LR(a, b):
           c = b.right
           a.left, b.right = c.right, c.left
           c.left, c.right = b, a
           if c.bf == 0:  # c 本身就是插入节点
               a.bf = b.bf = 0
           elif c.bf == 1:  # 新节点在c的左子树
               a.bf = -1
               b.bf = 0
           else:  # 新节点在c的右子树
               a.bf = 0
               b.bf = 1
           c.bf = 0
           return c
   ```

4. RL失衡和调整

   ```
   @staticmethod
       def RL(a, b):
           c = b.left
           a.right, b.left = c.left, c.right
           c.left, c.right = a, b
           if c.bf == 0:
               a.bf = b.bf = 0
           elif c.bf == 1:
               a.bf = 0
               b.bf = -1
           else:
               a.bf = 1
               b.bf = 0
           c.bf = 0
           return c
   ```

**插入操作的实现**

首先找到插入位置并实际插入新节点，然后可能需要修改一些节点的平衡因子，发现失衡时做一些局部调整（只需在最小不平衡子树的根节点附近左局部调整，不会影响其他部分，也不会改变树中数据的排序序列）

具体步骤：

- 查找新节点的插入位置，并在查找过程中记录遇到的最小不平衡子树的根，插入新节点。
- 修改从a的子节点到新节点的路径上各节点的平衡因子。
- 检查以a为根的子树是否失衡，失衡时做调整。
- 连接好调整后的子树，它可能该作为整棵树的根，或作为a原来的父节点的相应方向的子节点。（左或右节点）

代码实现：

```
def insert(self, key, value):
    """
    1. 查找新节点的插入位置，并在查找过程中记录遇到的最小不平衡子树的根，插入新节点。
    2. 修改从a的子节点到新节点的路径上各节点的平衡因子。
    3. 检查以a为根的子树是否失衡，失衡时做调整。
    4. 连接好调整后的子树，它可能该作为整棵树的根，或作为a原来的父节点的相应方向的子节点。（左或右节点）
    """
    # 使用4个变量，分别记录插入位置最近的平衡因子非0节点、遍历的指针变量以及对应父节点
    a = p = self.root  # a记录距插入位置最近的平衡因子非0节点，p为遍历的指针变量
    # 若为空树，直接插入为根节点并返回
    if a is None:
        self.root = AVLNode(key, value)
        return
    a_parent = p_parent = None  # 维持 a_parent, p_parent 分别为a, p 的父节点, a,p为根节点时父节点为None

    # 使用p指针进行遍历，确定插入位置并记录最小非平衡树，p为None时到达插入位置
    while p is not None:
        if key == p.key:  # key存在，修改value值并结束
            p.value = value
            return
        if p.bf != 0: # 更新a记录的平衡因子非0节点
            a_parent, a = p_parent, p
        # 移动 p 指针，并在移动前更新父节点位置
        p_parent = p
        if key < p.key:
            p = p.left
        else:
            p = p.right

    # 插入新节点，p_parent是插入点的父节点， 此时的a_parent,a 记录最小非平衡树
    node = AVLNode(key, value)
    if key < p_parent.key:
        p_parent.left = node  # 作为左子节点插入
    else:
        p_parent.right = node  # 作为右子节点插入

    # 将p的位置重置到最小非平衡树a在插入新节点方向的子节点b， d为插入新节点后a的平衡因子的变化值
    # 新节点在a的左子树， 平衡因子+1
    if key < a.key:
        p = b = a.left
        bf_change = 1
    # 新节点在a的右子树， 平衡因子-1
    else:
        p = b = a.right
        bf_change = -1

    # 修改b到新节点路径上各节点的BF值，b为a的子节点
    while p != node:
        if key < p.key:  # 新节点插入在左侧，p的左子树增高（原bf值为0）
            p.bf = 1
            p = p.left
        else:  # p的右子树增高
            p.bf = -1
            p = p.right
    if a.bf == 0:  # a 的原BF为0，不会失衡，直接返回
        a.bf = bf_change
        return
    if a.bf == -bf_change:  # 新节点插入在较低子树里，不会失衡，直接返回
        a.bf = 0
        return

    # 新节点插入在较高子树，失衡，必须调整
    # 根据bf_change和b的bf值判断失衡类别，并进行调整，返回调整后的子树根节点
    if bf_change == 1:  # 新节点在a的左子树
        if b.bf == 1:
            b = AVLTree.LL(a, b)  # LL调整
        else:
            b = AVLTree.LR(a, b)  # LR调整
    else:  # 新节点在a的右子树
        if b.bf == -1:
            b = AVLTree.RR(a, b)  # RR调整
        else:
            b = AVLTree.RL(a, b)  # RL调整

    # 连接调整好后的子树
    if a_parent is None:  # 原a为树根，修改root节点
        self.root = b
    else:  # a不是根节点，新树接在正确位置
        if a_parent.left == a:
            a_parent.left = b
        else:
            a_parent.right = b
```

### 5.4 各种平衡二叉树的对比

绝大部分情况下Treap、Splay Tree操作的效率都很高，但是也无法避免极端情况下时间复杂度的退化。尽管这种情况出现的概率不大，但是对于单次操作时间非常敏感的场景来说，它们并不适用。

AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但AVL 树为了维持这种高度的平衡，每次插入、删除都要做调整**比较复杂、耗时。**对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高。

红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比 AVL 树要低。红黑树的插入、删除、查找各种操作性能都比较稳定。对于工程应用来说，要面对各种异常情况，为了支撑这种工业级的应用更倾向于这种性能稳定的平衡二叉查找树。

### 5.5 动态数据结构优劣势对比

动态数据结构支持动态地数据插入、删除、查找操作

散列表：插入删除查找都是O(1), 是最常用的，但其缺点是不能顺序遍历以及扩容缩容的性能损耗。适用于那些不需要顺序遍历，数据更新不那么频繁的。

跳表：插入删除查找都是O(logn), 并且能顺序遍历。缺点是空间复杂度O(n)。适用于不那么在意内存空间的，其顺序遍历和区间查找非常方便。

红黑树：插入删除查找都是O(logn), 中序遍历即是顺序遍历，稳定。缺点是难以实现，去查找不方便。 

## 6、B树与B+树

### 6.1 B与B+树的思考

#### 1.理清需求

对于数据库两个最基本的查询需求：

- 根据某个值查找数据，比如 select * from user where id=1234；
- 根据区间值来查找某些数据，比如 select * from user where id > 1234 and id < 2345。

即单值查找和区间查找。

#### 2. 尝试用已知的数据结构解决这个问题

根据前面的学习，支持快速查询、插入等操作的动态数据结构有散列表、平衡二叉查找树、跳表。

先看**散列表**，散列表的查询性能的时间复杂度是 O(1)，但散列表不能支持按照区间快速查找数据，所以散列表不能满足需求。

再看**平衡二叉查找树**，查询性能时间复杂度是 O(logn)。对树进行中序遍历可以得到一个从小到大有序的数据序列，但不支持按照区间快速查找数据。

最后看**跳表**。跳表是在链表之上加上多层索引构成的。它支持快速地插入、查找、删除数据，对应的时间复杂度是 O(logn)。并且，跳表也支持按照区间快速地查找数据。只需要定位到区间起点值对应在链表中的结点，然后从这个结点开始，顺序遍历链表，直到区间终点对应的结点为止，这期间遍历得到的数据就是满足区间值的数据。

![1570506827342](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506827342.png)

#### 3. 改造二叉查找树来解决这个问题

结合平衡二叉查找树和跳表的优点进行改造：树中的节点并不存储数据本身，而是只是作为索引。另外，把每个叶子节点串在一条链表上，链表中的数据是从小到大有序的。

如下图：

为了让二叉查找树支持按照区间来查找数据，我们可以对它进行这样的改造：树中的节点并不存储数据本身，而是只是作为索引。除此之外，我们把每个叶子节点串在一条链表上，链表中的数据是从小到大有序的。经过改造之后的二叉树，就像图中这样，看起来是不是很像跳表呢？

![1570506847019](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506847019.png)

改造之后要求某个区间的数据，只需要拿区间的起始值，在树中进行查找，当查找到某个叶子节点之后，我们再顺着链表往后遍历，直到链表中的结点数据值大于区间的终止值为止。所有遍历到的数据，就是符合区间值的所有数据。

![1570506862261](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506862261.png)



索引的内存占用可能比较高，比如给一亿个数据构建二叉查找树索引，那索引中会包含大约 1 亿个节点，每个节点假设占用 16 个字节，那就需要大约 1GB 的内存空间。给一张表建立索引，需要 1GB 的内存空间。如果要给10 张表建立索引，内存就可能超过了单台机器的承受极限。

### 6.2 概述

维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B-树为系统最优化**大块数据的读和写操作**。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在**数据库**和**文件系统**。”

**定义： B 树**可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。

- 根节点至少有两个子节点
- 每个节点有M-1个key，并且以升序排列
- 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间
- 其它节点至少有M/2个子节点

### 6.3 B树增加与删除节点

**删除**



![IMG_1702](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/IMG_1702.jpeg)

**增加节点**

![img](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/btreebuild.gif)



### 6.4 B+树的插入和删除操作

**插入操作**

对于一个 B+ 树来说，m 值是根据页的大小事先计算好的，也就是说，每个节点最多只能有 m 个子节点。

在写入数据的过程中，有可能使索引中某些节点的子节点个数超过 m，这个节点的大小超过了一个页的大小，读取这样一个节点，就会导致多次磁盘 IO 操作。这时只需要将这个节点分裂成两个节点。但是，节点分裂之后，其上层父节点的子节点个数就有可能超过 m 个，需要再将父节点也分裂成两个节点。这种级联反应会从下往上，一直影响到根节点。

插入数据的分裂过程：

![1570506939090](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506939090.png)

（图中的 B+ 树是一个三叉树。限定叶子节点中，数据的个数超过 2 个就分裂节点；非叶子节点中，子节点的个数超过 3 个就分裂节点）

![img](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/Bplustreebuild.gif)

**删除操作**

删除数据时的索引更新：

删除某个数据的时候，也要对应的更新索引节点。这个处理思路有点类似跳表中删除数据的处理思路。频繁的数据删除，就会导致某些结点中，子节点的个数变得非常少，长此以往，如果每个节点的子节点都比较少，势必会影响索引的效率。

可以设置一个阈值。在 B+ 树中，这个阈值等于 m/2。如果某个节点的子节点个数小于m/2，就将它跟相邻的兄弟节点合并。不过，合并之后结点的子节点个数有可能会超过 m。针对这种情况，可以借助插入数据时候的处理方法，再分裂节点。

删除操作的合并过程：

![1570506958575](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506958575.png)

（图中的 B+ 树是一个五叉树。我们限定叶子节点中，数据的个数少于 2 个就合并节点；非叶子节点中，子节点的个数少于 3 个就合并节点。）



### 6.5 B+树的特点

- 每个节点中子节点的个数不能超过 m，也不能小于 m/2；
- 根节点的子节点个数可以不超过 m/2，这是一个例外；
- m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；
- 通过链表将叶子节点串联在一起，这样可以方便按区间查找；
- 一般情况，根节点会被存储在内存中，其他节点存储在磁盘中。

### 6.6 B树&B+树

B-树就是B树，英文翻译都是 B-Tree，这里的“-”并不是相对 B+ 树中的“+”，而只是一个连接符。

而 B 树实际上是低级版的 B+ 树，或者说 B+ 树是 B 树的改进版。B 树跟 B+ 树的不同点主要集中在这几个地方：

- B+ 树中的节点不存储数据，只是索引，而 B 树中的节点存储数据；
- B 树中的叶子节点并不需要链表来串联。

也就是说，B 树只是一个每个节点的子节点个数不能小于 m/2 的 m 叉树。

### 6.7 如何优化减少索引的内存占用呢？

可以借助时间换空间的思路，把索引存储在硬盘中，而非内存中。但硬盘是一个非常慢速的存储设备。通常内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的。读取同样大小的数据，从磁盘中读取花费的时间，是从内存中读取所花费时间的上万倍，甚至几十万倍。

把树结构的索引存储在硬盘中，在数据查找的过程中需读取n个树节点（n表示树的高度），每个节点的读取（或者访问）都对应一次磁盘IO操作，即每次查询数据时磁盘IO操作的次数就等于树的高度。

那么只要降低树的高度就可以减少磁盘 IO次数。

### 6.8 如何降低树的高度呢？

如果把索引构建成m叉树，高度是不是比二叉树要小呢？

比如下图，给16个数据构建二叉树索引，树的高度是 4。如果构建五叉树索引，那高度只有 2。

如果 m 叉树中的 m 是 100，那对一亿个数据构建索引，树的高度也只是3。

![1570506881996](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506881996.png)



### 6.9 构建m叉树索引m多大最合适呢？

不管是内存中的数据，还是磁盘中的数据，操作系统都是按页（一页大小通常是 4KB，这个值可以通过 getconfig PAGE_SIZE 命令查看）来读取的，一次会读一页的数据。如果要读取的数据量超过一页的大小，就会触发多次 IO 操作。所以，在选择 m 大小的时候，要尽量让每个节点的大小等于一个页的大小。读取一个节点，只需要一次磁盘 IO 操作。

![1570506917393](%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%AC%AC%E5%85%AD%E7%AF%87.%E6%A0%91.assets/1570506917393.png)

## 7、红黑树

咱不会！！！！！！！

